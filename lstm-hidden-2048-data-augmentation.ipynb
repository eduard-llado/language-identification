{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5e450ba",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-04-16T21:29:07.288255Z",
     "iopub.status.busy": "2022-04-16T21:29:07.287468Z",
     "iopub.status.idle": "2022-04-16T21:29:10.627632Z",
     "shell.execute_reply": "2022-04-16T21:29:10.626873Z",
     "shell.execute_reply.started": "2022-04-16T21:24:58.379737Z"
    },
    "papermill": {
     "duration": 3.3816,
     "end_time": "2022-04-16T21:29:10.627784",
     "exception": false,
     "start_time": "2022-04-16T21:29:07.246184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Scripts.txt', 'x_train.txt', 'x_test.txt', 'y_train.txt', 'labels.csv']\n",
      "Example:\n",
      "LANG = est\n",
      "TEXT = Klement Gottwaldi surnukeha palsameeriti ning paigutati mausoleumi. Surnukeha oli aga liiga hilja ja oskamatult palsameeritud ning hakkas ilmutama lagunemise tundemärke. 1962. aastal viidi ta surnukeha mausoleumist ära ja kremeeriti. Zlíni linn kandis aastatel 1949–1989 nime Gottwaldov. Ukrainas Harkivi oblastis kandis Zmiivi linn aastatel 1976–1990 nime Gotvald.\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "import random\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch # Deep learning framework\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "# import torch_xla\n",
    "# import torch_xla.core.xla_model as xm\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "import os\n",
    "INPUTDIR = '../input/wili5'\n",
    "print(os.listdir(f'{INPUTDIR}'))\n",
    "\n",
    "#Init random seed to get reproducible results\n",
    "seed = 1111\n",
    "random.seed(seed)\n",
    "np.random.RandomState(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "x_train_full = open(f'{INPUTDIR}/x_train.txt').read().splitlines()\n",
    "y_train_full = open(f'{INPUTDIR}/y_train.txt').read().splitlines()\n",
    "print('Example:')\n",
    "print('LANG =', y_train_full[0])\n",
    "print('TEXT =', x_train_full[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a21ca3ab",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2022-04-16T21:29:10.706381Z",
     "iopub.status.busy": "2022-04-16T21:29:10.705499Z",
     "iopub.status.idle": "2022-04-16T21:29:10.708768Z",
     "shell.execute_reply": "2022-04-16T21:29:10.708247Z",
     "shell.execute_reply.started": "2022-04-16T21:25:13.122570Z"
    },
    "papermill": {
     "duration": 0.047408,
     "end_time": "2022-04-16T21:29:10.708881",
     "exception": false,
     "start_time": "2022-04-16T21:29:10.661473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Dictionary(object):\n",
    "    def __init__(self):\n",
    "        self.token2idx = {}\n",
    "        self.idx2token = []\n",
    "\n",
    "    def add_token(self, token):\n",
    "        if token not in self.token2idx:\n",
    "            self.idx2token.append(token)\n",
    "            self.token2idx[token] = len(self.idx2token) - 1\n",
    "        return self.token2idx[token]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx2token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5336e423",
   "metadata": {
    "papermill": {
     "duration": 0.031192,
     "end_time": "2022-04-16T21:29:10.771416",
     "exception": false,
     "start_time": "2022-04-16T21:29:10.740224",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The **Dictionary** class is used to map tokens (characters, words, subwords) into consecutive integer indexes.  \n",
    "The index **0** is reserved for padding sequences up to a fixed lenght, and the index **1** for any 'unknown' character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f31bd308",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-16T21:29:12.259824Z",
     "iopub.status.busy": "2022-04-16T21:29:12.248549Z",
     "iopub.status.idle": "2022-04-16T21:29:12.271000Z",
     "shell.execute_reply": "2022-04-16T21:29:12.270588Z",
     "shell.execute_reply.started": "2022-04-16T21:25:14.327886Z"
    },
    "papermill": {
     "duration": 1.465634,
     "end_time": "2022-04-16T21:29:12.271154",
     "exception": false,
     "start_time": "2022-04-16T21:29:10.805520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: 10808 UTF characters\n",
      "Labels: 235 languages\n"
     ]
    }
   ],
   "source": [
    "char_vocab = Dictionary()\n",
    "pad_token = '<pad>' # reserve index 0 for padding\n",
    "unk_token = '<unk>' # reserve index 1 for unknown token\n",
    "pad_index = char_vocab.add_token(pad_token)\n",
    "unk_index = char_vocab.add_token(unk_token)\n",
    "\n",
    "# join all the training sentences in a single string\n",
    "# and obtain the list of different characters with set\n",
    "chars = set(''.join(x_train_full))\n",
    "for char in sorted(chars):\n",
    "    char_vocab.add_token(char)\n",
    "print(\"Vocabulary:\", len(char_vocab), \"UTF characters\")\n",
    "\n",
    "lang_vocab = Dictionary()\n",
    "# use python set to obtain the list of languages without repetitions\n",
    "languages = set(y_train_full)\n",
    "for lang in sorted(languages):\n",
    "    lang_vocab.add_token(lang)\n",
    "print(\"Labels:\", len(lang_vocab), \"languages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59a83e75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-16T21:29:12.417819Z",
     "iopub.status.busy": "2022-04-16T21:29:12.382068Z",
     "iopub.status.idle": "2022-04-16T21:29:12.697649Z",
     "shell.execute_reply": "2022-04-16T21:29:12.696971Z",
     "shell.execute_reply.started": "2022-04-16T21:25:14.540863Z"
    },
    "papermill": {
     "duration": 0.397577,
     "end_time": "2022-04-16T21:29:12.697791",
     "exception": false,
     "start_time": "2022-04-16T21:29:12.300214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use only sentences of size 128\n",
    "x_train = []\n",
    "y_train = []\n",
    "for x, y in zip(x_train_full, y_train_full):\n",
    "    for i in range(0, len(x) - 128 + 1, 64):\n",
    "        x_train.append(x[i:i+128])\n",
    "        y_train.append(y)\n",
    "        \n",
    "x_train_full = x_train\n",
    "y_train_full = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ffd0db6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-16T21:29:12.758021Z",
     "iopub.status.busy": "2022-04-16T21:29:12.757246Z",
     "iopub.status.idle": "2022-04-16T21:29:27.712634Z",
     "shell.execute_reply": "2022-04-16T21:29:27.713061Z",
     "shell.execute_reply.started": "2022-04-16T21:25:14.744467Z"
    },
    "papermill": {
     "duration": 14.986668,
     "end_time": "2022-04-16T21:29:27.713213",
     "exception": false,
     "start_time": "2022-04-16T21:29:12.726545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a -> 67\n",
      "cat -> 28\n",
      "est Klement Go\n",
      "52 [45 78 71 79 71 80 86  2 41 81]\n"
     ]
    }
   ],
   "source": [
    "#From token or label to index\n",
    "print('a ->', char_vocab.token2idx['a'])\n",
    "print('cat ->', lang_vocab.token2idx['cat'])\n",
    "print(y_train_full[0], x_train_full[0][:10])\n",
    "x_train_idx = [np.array([char_vocab.token2idx[c] for c in line]) for line in x_train_full]\n",
    "y_train_idx = np.array([lang_vocab.token2idx[lang] for lang in y_train_full])\n",
    "print(y_train_idx[0], x_train_idx[0][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e120ce21",
   "metadata": {
    "papermill": {
     "duration": 0.029019,
     "end_time": "2022-04-16T21:29:27.771663",
     "exception": false,
     "start_time": "2022-04-16T21:29:27.742644",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Radomly select 15% of the database for validation  \n",
    "Create lists of (input, target) tuples for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a393ee7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-16T21:29:27.844178Z",
     "iopub.status.busy": "2022-04-16T21:29:27.843493Z",
     "iopub.status.idle": "2022-04-16T21:29:28.988085Z",
     "shell.execute_reply": "2022-04-16T21:29:28.987532Z",
     "shell.execute_reply.started": "2022-04-16T21:25:15.206371Z"
    },
    "papermill": {
     "duration": 1.178704,
     "end_time": "2022-04-16T21:29:28.988211",
     "exception": false,
     "start_time": "2022-04-16T21:29:27.809507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426983 training samples\n",
      "75350 validation samples\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_idx, y_train_idx, test_size=0.15, random_state=seed)\n",
    "train_data = [(x, y) for x, y in zip(x_train, y_train)]\n",
    "val_data = [(x, y) for x, y in zip(x_val, y_val)]\n",
    "print(len(train_data), \"training samples\")\n",
    "print(len(val_data), \"validation samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10833160",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-16T21:29:29.056308Z",
     "iopub.status.busy": "2022-04-16T21:29:29.055562Z",
     "iopub.status.idle": "2022-04-16T21:29:29.057531Z",
     "shell.execute_reply": "2022-04-16T21:29:29.057888Z",
     "shell.execute_reply.started": "2022-04-16T21:25:16.001282Z"
    },
    "papermill": {
     "duration": 0.039379,
     "end_time": "2022-04-16T21:29:29.058021",
     "exception": false,
     "start_time": "2022-04-16T21:29:29.018642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def batch_generator(data, batch_size, token_size):\n",
    "    \"\"\"Yield elements from data in chunks with a maximum of batch_size sequences and token_size tokens.\"\"\"\n",
    "    minibatch, sequences_so_far, tokens_so_far = [], 0, 0\n",
    "    for ex in data:\n",
    "        seq_len = len(ex[0])\n",
    "        if seq_len > token_size:\n",
    "            ex = (ex[0][:token_size], ex[1])\n",
    "            seq_len = token_size\n",
    "        minibatch.append(ex)\n",
    "        sequences_so_far += 1\n",
    "        tokens_so_far += seq_len\n",
    "        if sequences_so_far == batch_size or tokens_so_far == token_size:\n",
    "            yield minibatch\n",
    "            minibatch, sequences_so_far, tokens_so_far = [], 0, 0\n",
    "        elif sequences_so_far > batch_size or tokens_so_far > token_size:\n",
    "            yield minibatch[:-1]\n",
    "            minibatch, sequences_so_far, tokens_so_far = minibatch[-1:], 1, len(minibatch[-1][0])\n",
    "    if minibatch:\n",
    "        yield minibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee3435e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-16T21:29:29.123663Z",
     "iopub.status.busy": "2022-04-16T21:29:29.122961Z",
     "iopub.status.idle": "2022-04-16T21:29:29.125456Z",
     "shell.execute_reply": "2022-04-16T21:29:29.125054Z",
     "shell.execute_reply.started": "2022-04-16T21:25:16.012285Z"
    },
    "papermill": {
     "duration": 0.037615,
     "end_time": "2022-04-16T21:29:29.125561",
     "exception": false,
     "start_time": "2022-04-16T21:29:29.087946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pool_generator(data, batch_size, token_size, shuffle=False):\n",
    "    \"\"\"Sort within buckets, then batch, then shuffle batches.\n",
    "    Partitions data into chunks of size 100*token_size, sorts examples within\n",
    "    each chunk, then batch these examples and shuffle the batches.\n",
    "    \"\"\"\n",
    "    for p in batch_generator(data, batch_size * 100, token_size * 100):\n",
    "        p_batch = batch_generator(sorted(p, key=lambda t: len(t[0]), reverse=True), batch_size, token_size)\n",
    "        p_list = list(p_batch)\n",
    "        if shuffle:\n",
    "            for b in random.sample(p_list, len(p_list)):\n",
    "                yield b\n",
    "        else:\n",
    "            for b in p_list:\n",
    "                yield b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7696e02e",
   "metadata": {
    "papermill": {
     "duration": 0.029131,
     "end_time": "2022-04-16T21:29:29.183991",
     "exception": false,
     "start_time": "2022-04-16T21:29:29.154860",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**DNN Model**  \n",
    "Includes Python comments with the dimension of the input  matrix:  \n",
    "T = Max number of tokens in a sequence  \n",
    "B = Number of sequences (batch size)  \n",
    "E = Embedding dim  \n",
    "H = Hidden size  \n",
    "O = Output size (number of languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6cdd3e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-16T21:29:29.245682Z",
     "iopub.status.busy": "2022-04-16T21:29:29.244902Z",
     "iopub.status.idle": "2022-04-16T21:29:29.254023Z",
     "shell.execute_reply": "2022-04-16T21:29:29.253580Z",
     "shell.execute_reply.started": "2022-04-16T21:25:16.021425Z"
    },
    "papermill": {
     "duration": 0.040683,
     "end_time": "2022-04-16T21:29:29.254149",
     "exception": false,
     "start_time": "2022-04-16T21:29:29.213466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CharRNNClassifier(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, model=\"lstm\", num_layers=1, bidirectional=False, pad_idx=0):\n",
    "        super().__init__()\n",
    "        self.model = model.lower()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embed = torch.nn.Embedding(input_size, embedding_size, padding_idx=pad_idx)\n",
    "        if self.model == \"gru\":\n",
    "            self.rnn = torch.nn.GRU(embedding_size, hidden_size, num_layers, bidirectional=bidirectional)\n",
    "        elif self.model == \"lstm\":\n",
    "            self.rnn = torch.nn.LSTM(embedding_size, hidden_size, num_layers, bidirectional=bidirectional)\n",
    "        self.h2o = torch.nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, input, input_lengths):\n",
    "        # T x B\n",
    "        encoded = self.embed(input)\n",
    "        # T x B x E\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(encoded, input_lengths)\n",
    "        # Packed T x B x E\n",
    "        output, _ = self.rnn(packed)\n",
    "        # Packed T x B x H\n",
    "        # Important: you may need to replace '-inf' with the default zero padding for other pooling layers\n",
    "        padded, _ = torch.nn.utils.rnn.pad_packed_sequence(output, padding_value=float('-inf'))\n",
    "        # T x B x H\n",
    "        output, _ = padded.max(dim=0)\n",
    "        # B x H\n",
    "        output = self.h2o(output)\n",
    "        # B x O\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d4ebb13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-16T21:29:29.373950Z",
     "iopub.status.busy": "2022-04-16T21:29:29.373333Z",
     "iopub.status.idle": "2022-04-16T21:29:29.375888Z",
     "shell.execute_reply": "2022-04-16T21:29:29.376375Z",
     "shell.execute_reply.started": "2022-04-16T21:25:16.034209Z"
    },
    "papermill": {
     "duration": 0.092966,
     "end_time": "2022-04-16T21:29:29.376507",
     "exception": false,
     "start_time": "2022-04-16T21:29:29.283541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    print(\"WARNING: CUDA is not available. Select 'GPU On' on kernel settings\")\n",
    "device = torch.device(\"cuda\")\n",
    "torch.cuda.manual_seed(seed)\n",
    "# device = xm.xla_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eed2f67",
   "metadata": {
    "papermill": {
     "duration": 0.029769,
     "end_time": "2022-04-16T21:29:29.435848",
     "exception": false,
     "start_time": "2022-04-16T21:29:29.406079",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The **nn.CrossEntropyLoss()** criterion combines **nn.LogSoftmax()** and **nn.NLLLoss()** in one single class.  \n",
    "It is useful when training a classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "319a8cab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-16T21:29:29.499537Z",
     "iopub.status.busy": "2022-04-16T21:29:29.498839Z",
     "iopub.status.idle": "2022-04-16T21:29:29.501366Z",
     "shell.execute_reply": "2022-04-16T21:29:29.500926Z",
     "shell.execute_reply.started": "2022-04-16T21:25:16.459695Z"
    },
    "papermill": {
     "duration": 0.036007,
     "end_time": "2022-04-16T21:29:29.501478",
     "exception": false,
     "start_time": "2022-04-16T21:29:29.465471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62b55dc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-16T21:29:29.571077Z",
     "iopub.status.busy": "2022-04-16T21:29:29.570284Z",
     "iopub.status.idle": "2022-04-16T21:29:29.572190Z",
     "shell.execute_reply": "2022-04-16T21:29:29.572592Z",
     "shell.execute_reply.started": "2022-04-16T21:25:16.655479Z"
    },
    "papermill": {
     "duration": 0.041187,
     "end_time": "2022-04-16T21:29:29.572707",
     "exception": false,
     "start_time": "2022-04-16T21:29:29.531520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, data, batch_size, token_size, max_norm=1, log=False):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    ncorrect = 0\n",
    "    nsentences = 0\n",
    "    ntokens = 0\n",
    "    niterations = 0\n",
    "    for batch in pool_generator(data, batch_size, token_size, shuffle=True):\n",
    "        # Get input and target sequences from batch\n",
    "        X = [torch.from_numpy(d[0]) for d in batch]\n",
    "        X_lengths = [x.numel() for x in X]\n",
    "        ntokens += sum(X_lengths)\n",
    "        X_lengths = torch.tensor(X_lengths, dtype=torch.long)\n",
    "        y = torch.tensor([d[1] for d in batch], dtype=torch.long, device=device)\n",
    "        # Pad the input sequences to create a matrix\n",
    "        X = torch.nn.utils.rnn.pad_sequence(X).to(device)\n",
    "        model.zero_grad()\n",
    "        output = model(X, X_lengths)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)      # Gradient clipping https://www.kaggle.com/c/wili4/discussion/231378\n",
    "        optimizer.step()\n",
    "        # xm.optimizer_step(optimizer, barrier=True)\n",
    "        # Training statistics\n",
    "        total_loss += loss.item()\n",
    "        ncorrect += (torch.max(output, 1)[1] == y).sum().item()\n",
    "        nsentences += y.numel()\n",
    "        niterations += 1\n",
    "    \n",
    "    total_loss = total_loss / nsentences\n",
    "    accuracy = 100 * ncorrect / nsentences\n",
    "    if log:\n",
    "        print(f'Train: wpb={ntokens//niterations}, bsz={nsentences//niterations}, num_updates={niterations}')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e299be7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-16T21:29:29.639158Z",
     "iopub.status.busy": "2022-04-16T21:29:29.638395Z",
     "iopub.status.idle": "2022-04-16T21:29:29.640371Z",
     "shell.execute_reply": "2022-04-16T21:29:29.640778Z",
     "shell.execute_reply.started": "2022-04-16T21:25:16.813182Z"
    },
    "papermill": {
     "duration": 0.038653,
     "end_time": "2022-04-16T21:29:29.640892",
     "exception": false,
     "start_time": "2022-04-16T21:29:29.602239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate(model, data, batch_size, token_size):\n",
    "    model.eval()\n",
    "    # calculate accuracy on validation set\n",
    "    ncorrect = 0\n",
    "    nsentences = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in pool_generator(data, batch_size, token_size):\n",
    "            # Get input and target sequences from batch\n",
    "            X = [torch.from_numpy(d[0]) for d in batch]\n",
    "            X_lengths = torch.tensor([x.numel() for x in X], dtype=torch.long)\n",
    "            y = torch.tensor([d[1] for d in batch], dtype=torch.long, device=device)\n",
    "            # Pad the input sequences to create a matrix\n",
    "            X = torch.nn.utils.rnn.pad_sequence(X).to(device)\n",
    "            answer = model(X, X_lengths)\n",
    "            ncorrect += (torch.max(answer, 1)[1] == y).sum().item()\n",
    "            nsentences += y.numel()\n",
    "        dev_acc = 100 * ncorrect / nsentences\n",
    "    return dev_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55581bde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-16T21:29:29.702790Z",
     "iopub.status.busy": "2022-04-16T21:29:29.701965Z",
     "iopub.status.idle": "2022-04-16T21:29:29.706365Z",
     "shell.execute_reply": "2022-04-16T21:29:29.705911Z",
     "shell.execute_reply.started": "2022-04-16T21:25:16.959672Z"
    },
    "papermill": {
     "duration": 0.035797,
     "end_time": "2022-04-16T21:29:29.706472",
     "exception": false,
     "start_time": "2022-04-16T21:29:29.670675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hidden_size = 2048\n",
    "embedding_size = 64\n",
    "bidirectional = False\n",
    "ntokens = len(char_vocab)\n",
    "nlabels = len(lang_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353fe20b",
   "metadata": {
    "papermill": {
     "duration": 0.029148,
     "end_time": "2022-04-16T21:29:29.765386",
     "exception": false,
     "start_time": "2022-04-16T21:29:29.736238",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Model for cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2e0b2d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-16T21:29:29.828700Z",
     "iopub.status.busy": "2022-04-16T21:29:29.827912Z",
     "iopub.status.idle": "2022-04-16T21:29:29.829783Z",
     "shell.execute_reply": "2022-04-16T21:29:29.830205Z",
     "shell.execute_reply.started": "2022-04-16T21:25:17.303274Z"
    },
    "papermill": {
     "duration": 0.035581,
     "end_time": "2022-04-16T21:29:29.830321",
     "exception": false,
     "start_time": "2022-04-16T21:29:29.794740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = CharRNNClassifier(ntokens, embedding_size, hidden_size, nlabels, bidirectional=bidirectional, pad_idx=pad_index).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5575fa0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-16T21:29:29.893866Z",
     "iopub.status.busy": "2022-04-16T21:29:29.893119Z",
     "iopub.status.idle": "2022-04-16T21:29:29.895435Z",
     "shell.execute_reply": "2022-04-16T21:29:29.894982Z",
     "shell.execute_reply.started": "2022-04-16T21:25:17.448011Z"
    },
    "papermill": {
     "duration": 0.035623,
     "end_time": "2022-04-16T21:29:29.895536",
     "exception": false,
     "start_time": "2022-04-16T21:29:29.859913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size, token_size = 256, 200000\n",
    "epochs = 25\n",
    "# train_accuracy = []\n",
    "# valid_accuracy = []\n",
    "# model, optimizer = get_model()\n",
    "# print(f'Training cross-validation model for {epochs} epochs')\n",
    "# t0 = time.time()\n",
    "# for epoch in range(1, epochs + 1):\n",
    "#     acc = train(model, optimizer, train_data, batch_size, token_size, log=epoch==1)\n",
    "#     train_accuracy.append(acc)\n",
    "#     print(f'| epoch {epoch:03d} | train accuracy={acc:.1f}% ({time.time() - t0:.0f}s)')\n",
    "#     acc = validate(model, val_data, batch_size, token_size)\n",
    "#     valid_accuracy.append(acc)\n",
    "#     print(f'| epoch {epoch:03d} | valid accuracy={acc:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee776006",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-16T21:29:29.957841Z",
     "iopub.status.busy": "2022-04-16T21:29:29.957104Z",
     "iopub.status.idle": "2022-04-16T21:29:29.959422Z",
     "shell.execute_reply": "2022-04-16T21:29:29.958988Z",
     "shell.execute_reply.started": "2022-04-16T21:25:17.629093Z"
    },
    "papermill": {
     "duration": 0.034533,
     "end_time": "2022-04-16T21:29:29.959519",
     "exception": false,
     "start_time": "2022-04-16T21:29:29.924986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(model)\n",
    "# for name, param in model.named_parameters():\n",
    "#     print(f'{name:20} {param.numel()} {list(param.shape)}')\n",
    "# print(f'TOTAL                {sum(p.numel() for p in model.parameters())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4b3ba1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-16T21:29:30.022258Z",
     "iopub.status.busy": "2022-04-16T21:29:30.021473Z",
     "iopub.status.idle": "2022-04-16T21:29:30.024906Z",
     "shell.execute_reply": "2022-04-16T21:29:30.024500Z",
     "shell.execute_reply.started": "2022-04-16T21:25:17.836891Z"
    },
    "papermill": {
     "duration": 0.035319,
     "end_time": "2022-04-16T21:29:30.025018",
     "exception": false,
     "start_time": "2022-04-16T21:29:29.989699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.plot(range(1, len(train_accuracy)+1), train_accuracy)\n",
    "# plt.plot(range(1, len(valid_accuracy)+1), valid_accuracy)\n",
    "# plt.xlabel('epoch')\n",
    "# plt.ylabel('Accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8d80da",
   "metadata": {
    "papermill": {
     "duration": 0.031284,
     "end_time": "2022-04-16T21:29:30.089133",
     "exception": false,
     "start_time": "2022-04-16T21:29:30.057849",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Final model**  \n",
    "Finally, we create a model using all the training data and we generate the submission with the predicted test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "907145d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-16T21:29:30.155949Z",
     "iopub.status.busy": "2022-04-16T21:29:30.155384Z",
     "iopub.status.idle": "2022-04-17T03:50:17.551291Z",
     "shell.execute_reply": "2022-04-17T03:50:17.551738Z",
     "shell.execute_reply.started": "2022-04-16T21:25:18.132396Z"
    },
    "papermill": {
     "duration": 22847.431536,
     "end_time": "2022-04-17T03:50:17.551899",
     "exception": false,
     "start_time": "2022-04-16T21:29:30.120363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training final model for 25 epochs\n",
      "Train: wpb=32755, bsz=255, num_updates=1963\n",
      "| epoch 001 | train accuracy=83.153 (914s)\n",
      "| epoch 002 | train accuracy=95.356 (1827s)\n",
      "| epoch 003 | train accuracy=97.522 (2741s)\n",
      "| epoch 004 | train accuracy=98.831 (3654s)\n",
      "| epoch 005 | train accuracy=99.418 (4567s)\n",
      "| epoch 006 | train accuracy=99.623 (5481s)\n",
      "| epoch 007 | train accuracy=99.692 (6394s)\n",
      "| epoch 008 | train accuracy=99.743 (7308s)\n",
      "| epoch 009 | train accuracy=99.786 (8222s)\n",
      "| epoch 010 | train accuracy=99.808 (9136s)\n",
      "| epoch 011 | train accuracy=99.834 (10050s)\n",
      "| epoch 012 | train accuracy=99.843 (10964s)\n",
      "| epoch 013 | train accuracy=99.848 (11877s)\n",
      "| epoch 014 | train accuracy=99.853 (12791s)\n",
      "| epoch 015 | train accuracy=99.853 (13705s)\n",
      "| epoch 016 | train accuracy=99.859 (14619s)\n",
      "| epoch 017 | train accuracy=99.880 (15533s)\n",
      "| epoch 018 | train accuracy=99.878 (16446s)\n",
      "| epoch 019 | train accuracy=99.879 (17360s)\n",
      "| epoch 020 | train accuracy=99.891 (18274s)\n",
      "| epoch 021 | train accuracy=99.893 (19188s)\n",
      "| epoch 022 | train accuracy=99.886 (20102s)\n",
      "| epoch 023 | train accuracy=99.891 (21016s)\n",
      "| epoch 024 | train accuracy=99.896 (21930s)\n",
      "| epoch 025 | train accuracy=99.887 (22844s)\n"
     ]
    }
   ],
   "source": [
    "print(f'Training final model for {epochs} epochs')\n",
    "model, optimizer = get_model()\n",
    "t0 = time.time()\n",
    "for epoch in range(1, epochs + 1):\n",
    "    acc = train(model, optimizer, train_data + val_data, batch_size, token_size, log=epoch==1)\n",
    "    print(f'| epoch {epoch:03d} | train accuracy={acc:.3f} ({time.time() - t0:.0f}s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4dfd9e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T03:50:17.632286Z",
     "iopub.status.busy": "2022-04-17T03:50:17.631693Z",
     "iopub.status.idle": "2022-04-17T03:50:17.837115Z",
     "shell.execute_reply": "2022-04-17T03:50:17.836603Z",
     "shell.execute_reply.started": "2022-04-16T21:26:05.185801Z"
    },
    "papermill": {
     "duration": 0.24709,
     "end_time": "2022-04-17T03:50:17.837265",
     "exception": false,
     "start_time": "2022-04-17T03:50:17.590175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d76da682",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T03:50:17.921192Z",
     "iopub.status.busy": "2022-04-17T03:50:17.920547Z",
     "iopub.status.idle": "2022-04-17T03:50:17.923264Z",
     "shell.execute_reply": "2022-04-17T03:50:17.922852Z",
     "shell.execute_reply.started": "2022-04-16T21:26:06.039946Z"
    },
    "papermill": {
     "duration": 0.046889,
     "end_time": "2022-04-17T03:50:17.923370",
     "exception": false,
     "start_time": "2022-04-17T03:50:17.876481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(model, data, batch_size, token_size):\n",
    "    model.eval()\n",
    "    sindex = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in pool_generator(data, batch_size, token_size):\n",
    "            # Get input sequences from batch\n",
    "            X = [torch.from_numpy(d[0]) for d in batch]\n",
    "            X_lengths = torch.tensor([x.numel() for x in X], dtype=torch.long)\n",
    "            # Pad the input sequences to create a matrix\n",
    "            X = torch.nn.utils.rnn.pad_sequence(X).to(device)\n",
    "            answer = model(X, X_lengths)\n",
    "            label = torch.max(answer, 1)[1].cpu().numpy()\n",
    "            # Save labels and sentences index\n",
    "            labels.append(label)\n",
    "            sindex += [d[1] for d in batch]\n",
    "    return np.array(sindex), np.concatenate(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d93ac94",
   "metadata": {
    "papermill": {
     "duration": 0.037782,
     "end_time": "2022-04-17T03:50:17.998245",
     "exception": false,
     "start_time": "2022-04-17T03:50:17.960463",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In the test database we replace the label (language) with a sentence index.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df574476",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T03:50:18.079048Z",
     "iopub.status.busy": "2022-04-17T03:50:18.078364Z",
     "iopub.status.idle": "2022-04-17T03:50:33.579190Z",
     "shell.execute_reply": "2022-04-17T03:50:33.578656Z",
     "shell.execute_reply.started": "2022-04-16T21:27:03.365226Z"
    },
    "papermill": {
     "duration": 15.543557,
     "end_time": "2022-04-17T03:50:33.579344",
     "exception": false,
     "start_time": "2022-04-17T03:50:18.035787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_test_txt = open(f'{INPUTDIR}/x_test.txt').read().splitlines()\n",
    "x_test_idx = [np.array([char_vocab.token2idx[c] if c in char_vocab.token2idx else unk_index for c in line])[:2048] for line in x_test_txt]  # Only 2048 so it fits in GPU\n",
    "test_data = [(x, idx) for idx, x in enumerate(x_test_idx)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63df2c5b",
   "metadata": {
    "papermill": {
     "duration": 0.039839,
     "end_time": "2022-04-17T03:50:33.660581",
     "exception": false,
     "start_time": "2022-04-17T03:50:33.620742",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The sentence index is used to rearrange the labels in the original sentence order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eada8bfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T03:50:33.786946Z",
     "iopub.status.busy": "2022-04-17T03:50:33.786075Z",
     "iopub.status.idle": "2022-04-17T03:54:14.603231Z",
     "shell.execute_reply": "2022-04-17T03:54:14.602719Z",
     "shell.execute_reply.started": "2022-04-16T21:27:05.210802Z"
    },
    "papermill": {
     "duration": 220.902726,
     "end_time": "2022-04-17T03:54:14.603376",
     "exception": false,
     "start_time": "2022-04-17T03:50:33.700650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "index, labels = test(model, test_data, batch_size, token_size)\n",
    "order = np.argsort(index)\n",
    "labels = labels[order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d12cdc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T03:54:14.686807Z",
     "iopub.status.busy": "2022-04-17T03:54:14.685915Z",
     "iopub.status.idle": "2022-04-17T03:54:14.825937Z",
     "shell.execute_reply": "2022-04-17T03:54:14.826446Z",
     "shell.execute_reply.started": "2022-04-16T21:27:11.016846Z"
    },
    "papermill": {
     "duration": 0.185085,
     "end_time": "2022-04-17T03:54:14.826617",
     "exception": false,
     "start_time": "2022-04-17T03:54:14.641532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,mwl\n",
      "1,nld\n",
      "2,ava\n",
      "3,tcy\n",
      "4,bjn\n",
      "5,mon\n",
      "6,glk\n",
      "7,lez\n",
      "8,bul\n",
      "9,nan\n"
     ]
    }
   ],
   "source": [
    "with open('submission.csv', 'w') as f:\n",
    "    print('Id,Language', file=f)\n",
    "    for sentence_id, lang_id in enumerate(labels):\n",
    "        language = lang_vocab.idx2token[lang_id]\n",
    "        if sentence_id < 10:\n",
    "            print(f'{sentence_id},{language}')\n",
    "        print(f'{sentence_id},{language}', file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a86833e",
   "metadata": {
    "papermill": {
     "duration": 0.039025,
     "end_time": "2022-04-17T03:54:14.905314",
     "exception": false,
     "start_time": "2022-04-17T03:54:14.866289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fcaff7",
   "metadata": {
    "papermill": {
     "duration": 0.039507,
     "end_time": "2022-04-17T03:54:14.984619",
     "exception": false,
     "start_time": "2022-04-17T03:54:14.945112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0252dfa9",
   "metadata": {
    "papermill": {
     "duration": 0.038964,
     "end_time": "2022-04-17T03:54:15.062715",
     "exception": false,
     "start_time": "2022-04-17T03:54:15.023751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35414a5f",
   "metadata": {
    "papermill": {
     "duration": 0.037779,
     "end_time": "2022-04-17T03:54:15.139572",
     "exception": false,
     "start_time": "2022-04-17T03:54:15.101793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337bb1f1",
   "metadata": {
    "papermill": {
     "duration": 0.039858,
     "end_time": "2022-04-17T03:54:15.220087",
     "exception": false,
     "start_time": "2022-04-17T03:54:15.180229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 23118.747212,
   "end_time": "2022-04-17T03:54:18.096653",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-16T21:28:59.349441",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
